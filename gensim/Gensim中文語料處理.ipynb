{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>下載中文維基數據</h1>\n",
    "\n",
    "<p>請前往維基百科:資料庫下載按日期來挑選更新的訓練資料。( 請挑選以pages-articles.xml.bz2為結尾的檔案 )</p>\n",
    "\n",
    "https://dumps.wikimedia.org/zhwiki/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-10-26 00:40:09,071 : INFO : Step1-開始輸出wiki_texts.txt\n",
      "2017-10-26 00:40:39,070 : INFO : 已處理 10000 篇文章\n",
      "2017-10-26 00:41:03,042 : INFO : 已處理 20000 篇文章\n",
      "2017-10-26 00:41:24,913 : INFO : 已處理 30000 篇文章\n",
      "2017-10-26 00:41:46,827 : INFO : 已處理 40000 篇文章\n",
      "2017-10-26 00:42:09,792 : INFO : 已處理 50000 篇文章\n",
      "2017-10-26 00:42:33,099 : INFO : 已處理 60000 篇文章\n",
      "2017-10-26 00:42:54,347 : INFO : 已處理 70000 篇文章\n",
      "2017-10-26 00:43:16,815 : INFO : 已處理 80000 篇文章\n",
      "2017-10-26 00:43:38,681 : INFO : 已處理 90000 篇文章\n",
      "2017-10-26 00:44:02,444 : INFO : 已處理 100000 篇文章\n",
      "2017-10-26 00:44:31,658 : INFO : 已處理 110000 篇文章\n",
      "2017-10-26 00:44:58,248 : INFO : 已處理 120000 篇文章\n",
      "2017-10-26 00:45:25,169 : INFO : 已處理 130000 篇文章\n",
      "2017-10-26 00:45:54,113 : INFO : 已處理 140000 篇文章\n",
      "2017-10-26 00:46:23,436 : INFO : 已處理 150000 篇文章\n",
      "2017-10-26 00:46:50,619 : INFO : 已處理 160000 篇文章\n",
      "2017-10-26 00:47:21,180 : INFO : 已處理 170000 篇文章\n",
      "2017-10-26 00:47:51,502 : INFO : 已處理 180000 篇文章\n",
      "2017-10-26 00:50:13,195 : INFO : 已處理 190000 篇文章\n",
      "2017-10-26 00:51:10,938 : INFO : 已處理 200000 篇文章\n",
      "2017-10-26 00:51:52,169 : INFO : 已處理 210000 篇文章\n",
      "2017-10-26 00:52:25,056 : INFO : 已處理 220000 篇文章\n",
      "2017-10-26 00:52:59,842 : INFO : 已處理 230000 篇文章\n",
      "2017-10-26 00:53:37,810 : INFO : 已處理 240000 篇文章\n",
      "2017-10-26 00:54:14,662 : INFO : 已處理 250000 篇文章\n",
      "2017-10-26 00:54:49,720 : INFO : 已處理 260000 篇文章\n",
      "2017-10-26 00:55:24,484 : INFO : 已處理 270000 篇文章\n",
      "2017-10-26 00:55:55,203 : INFO : 已處理 280000 篇文章\n",
      "2017-10-26 00:56:26,674 : INFO : 已處理 290000 篇文章\n",
      "2017-10-26 00:57:00,037 : INFO : 已處理 300000 篇文章\n",
      "2017-10-26 00:57:02,351 : INFO : finished iterating over Wikipedia corpus of 300644 documents with 67739708 positions (total 3029940 articles, 80711928 positions before pruning articles shorter than 50 words)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from gensim.corpora import WikiCorpus\n",
    "\n",
    "wikifile = 'zhwiki-20171020-pages-articles.xml.bz2'\n",
    "\n",
    "wiki_corpus = WikiCorpus(wikifile, dictionary={})\n",
    "texts_num = 0\n",
    "\n",
    "logging.info('Step1-開始輸出wiki_texts.txt')\n",
    "with open(\"wiki_texts.txt\",'w',encoding='utf-8') as output:\n",
    "    for text in wiki_corpus.get_texts():\n",
    "        output.write(' '.join(text) + '\\n')\n",
    "        texts_num += 1\n",
    "        if texts_num % 10000 == 0:\n",
    "            logging.info(\"已處理 %d 篇文章\" % texts_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>使用 OpenCC 將維基文章統一轉換為繁體中文</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"opencc -i wiki_texts.txt -o wiki_zh_tw.txt -c s2tw.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>使用jieba 對文本斷詞，並去除停用詞</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from /Users/dennislin/Documents/python/ChineseNLP/gensim/jieba_dict/dict.txt.big ...\n",
      "2017-10-27 00:01:17,203 : DEBUG : Building prefix dict from /Users/dennislin/Documents/python/ChineseNLP/gensim/jieba_dict/dict.txt.big ...\n",
      "Loading model from cache /var/folders/xk/jzfb6tps7kz7xv_j3tjr0h7c0000gn/T/jieba.u7727492867168ca4ad16b9668334ced9.cache\n",
      "2017-10-27 00:01:17,206 : DEBUG : Loading model from cache /var/folders/xk/jzfb6tps7kz7xv_j3tjr0h7c0000gn/T/jieba.u7727492867168ca4ad16b9668334ced9.cache\n",
      "Loading model cost 1.558 seconds.\n",
      "2017-10-27 00:01:18,763 : DEBUG : Loading model cost 1.558 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "2017-10-27 00:01:18,764 : DEBUG : Prefix dict has been built succesfully.\n",
      "2017-10-27 00:04:18,564 : INFO : 已完成前 10000 行的斷詞\n",
      "2017-10-27 00:06:30,138 : INFO : 已完成前 20000 行的斷詞\n",
      "2017-10-27 00:09:09,825 : INFO : 已完成前 30000 行的斷詞\n",
      "2017-10-27 00:12:03,769 : INFO : 已完成前 40000 行的斷詞\n",
      "2017-10-27 00:13:49,519 : INFO : 已完成前 50000 行的斷詞\n",
      "2017-10-27 00:15:49,395 : INFO : 已完成前 60000 行的斷詞\n",
      "2017-10-27 00:17:40,586 : INFO : 已完成前 70000 行的斷詞\n",
      "2017-10-27 00:19:12,426 : INFO : 已完成前 80000 行的斷詞\n",
      "2017-10-27 00:20:37,139 : INFO : 已完成前 90000 行的斷詞\n",
      "2017-10-27 00:22:05,034 : INFO : 已完成前 100000 行的斷詞\n",
      "2017-10-27 00:23:26,785 : INFO : 已完成前 110000 行的斷詞\n",
      "2017-10-27 00:24:41,471 : INFO : 已完成前 120000 行的斷詞\n",
      "2017-10-27 00:26:06,750 : INFO : 已完成前 130000 行的斷詞\n",
      "2017-10-27 00:27:28,477 : INFO : 已完成前 140000 行的斷詞\n",
      "2017-10-27 00:28:49,759 : INFO : 已完成前 150000 行的斷詞\n",
      "2017-10-27 00:30:10,387 : INFO : 已完成前 160000 行的斷詞\n",
      "2017-10-27 00:31:31,467 : INFO : 已完成前 170000 行的斷詞\n",
      "2017-10-27 00:32:46,966 : INFO : 已完成前 180000 行的斷詞\n",
      "2017-10-27 00:33:55,549 : INFO : 已完成前 190000 行的斷詞\n",
      "2017-10-27 00:35:15,043 : INFO : 已完成前 200000 行的斷詞\n",
      "2017-10-27 00:36:37,735 : INFO : 已完成前 210000 行的斷詞\n",
      "2017-10-27 00:38:00,615 : INFO : 已完成前 220000 行的斷詞\n",
      "2017-10-27 00:39:30,262 : INFO : 已完成前 230000 行的斷詞\n",
      "2017-10-27 00:41:04,575 : INFO : 已完成前 240000 行的斷詞\n",
      "2017-10-27 00:42:35,034 : INFO : 已完成前 250000 行的斷詞\n",
      "2017-10-27 00:44:09,605 : INFO : 已完成前 260000 行的斷詞\n",
      "2017-10-27 00:45:50,282 : INFO : 已完成前 270000 行的斷詞\n",
      "2017-10-27 00:47:17,247 : INFO : 已完成前 280000 行的斷詞\n",
      "2017-10-27 00:48:34,572 : INFO : 已完成前 290000 行的斷詞\n",
      "2017-10-27 00:49:47,730 : INFO : 已完成前 300000 行的斷詞\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import jieba\n",
    "import logging\n",
    "\n",
    "# jieba custom setting.\n",
    "jieba.set_dictionary('jieba_dict/dict.txt.big')\n",
    "\n",
    "# load stopwords set\n",
    "stopwordset = set()\n",
    "with open('jieba_dict/stopwords.txt','r',encoding='utf-8') as sw:\n",
    "    for line in sw:\n",
    "        stopwordset.add(line.strip('\\n'))\n",
    "\n",
    "texts_num = 0\n",
    "\n",
    "output = open('wiki_seg.txt','w')\n",
    "with open('wiki_zh_tw.txt','r') as content :\n",
    "    for line in content:\n",
    "        line = line.strip('\\n')\n",
    "        words = jieba.cut(line, cut_all=False)\n",
    "        for word in words:\n",
    "            if word not in stopwordset:\n",
    "                output.write(word +' ')\n",
    "\n",
    "        texts_num += 1\n",
    "        if texts_num % 10000 == 0:\n",
    "            logging.info(\"已完成前 %d 行的斷詞\" % texts_num)\n",
    "output.close()\n",
    "logging.info('已完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>使用gensim 的 word2vec 模型進行訓練</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "sentences = word2vec.Text8Corpus(\"wiki_seg.txt\")\n",
    "model = word2vec.Word2Vec(sentences, size=250)\n",
    "\n",
    "#保存模型，供日後使用\n",
    "model.save(\"med250.model.bin\")\n",
    "logging.info('已完成')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<h1>測試模型</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提供 3 種測試模式\n",
      "\n",
      "輸入一個詞，則去尋找前一百個該詞的相似詞\n",
      "輸入兩個詞，則去計算兩個詞的餘弦相似度\n",
      "輸入三個詞，進行類比推理\n",
      "漫威\n",
      "相似詞前 100 排序\n",
      "夜魔俠,0.6886358261108398\n",
      "marvel,0.6717044115066528\n",
      "水行俠,0.6563444137573242\n",
      "神奇四俠,0.6440639495849609\n",
      "蜘蛛人,0.6250507235527039\n",
      "死侍,0.6121244430541992\n",
      "復仇者,0.571926474571228\n",
      "蝙蝠俠,0.549408495426178\n",
      "皮克斯,0.5481370687484741\n",
      "綠箭俠,0.544106125831604\n",
      "蜘蛛俠,0.543834388256073\n",
      "孩之寶,0.5374860167503357\n",
      "制裁者,0.529426097869873\n",
      "閃電俠,0.5280251502990723\n",
      "浩克,0.5191125273704529\n",
      "deadpool,0.5160672664642334\n",
      "漫畫書,0.5153291821479797\n",
      "daredevil,0.5102291107177734\n",
      "前傳,0.5067425966262817\n",
      "batman,0.5054164528846741\n",
      "派拉蒙,0.5031026601791382\n",
      "戰警,0.5023834705352783\n",
      "懲罰者,0.4980250597000122\n",
      "奇航記,0.49494341015815735\n",
      "霹靂遊俠,0.49482306838035583\n",
      "強斯,0.4927905797958374\n",
      "樂高,0.49158456921577454\n",
      "dcau,0.49081557989120483\n",
      "惡棍,0.4886305630207062\n",
      "女超人,0.488104909658432\n",
      "夢工廠,0.4874275326728821\n",
      "夜翼,0.48529163002967834\n",
      "綠巨人,0.48446789383888245\n",
      "robotech,0.48386719822883606\n",
      "溫斯坦,0.4834345877170563\n",
      "返校日,0.48289328813552856\n",
      "星際,0.48150044679641724\n",
      "小勞勃,0.48102912306785583\n",
      "獅門,0.4810125231742859\n",
      "電子遊戲,0.4782177805900574\n",
      "道尼,0.4758148491382599\n",
      "史酷比,0.4728298783302307\n",
      "科幻電影,0.4718483090400696\n",
      "溫登,0.4710354208946228\n",
      "dc,0.4706200063228607\n",
      "lucasarts,0.46987590193748474\n",
      "路瑟,0.46904194355010986\n",
      "機械公敵,0.4678272306919098\n",
      "idw,0.4676714241504669\n",
      "星爵,0.46521833539009094\n",
      "hulk,0.4651685357093811\n",
      "改編權,0.4650081396102905\n",
      "黑暗世界,0.46484601497650146\n",
      "沙贊,0.46387648582458496\n",
      "pixar,0.45915815234184265\n",
      "星際爭霸,0.4579036235809326\n",
      "刀鋒戰士,0.45704925060272217\n",
      "avengers,0.45685210824012756\n",
      "史丹,0.45552247762680054\n",
      "鐵弋,0.4540911018848419\n",
      "驚奇,0.45287761092185974\n",
      "星艦,0.4525311291217804\n",
      "迪斯尼,0.4512157440185547\n",
      "universe,0.44993114471435547\n",
      "星戰,0.4493667185306549\n",
      "凱奇,0.44928643107414246\n",
      "史考特,0.44600075483322144\n",
      "佔士邦,0.44547584652900696\n",
      "貓和老鼠,0.44508248567581177\n",
      "科幻,0.44362711906433105\n",
      "變形金剛,0.4427594542503357\n",
      "星際大戰,0.44152215123176575\n",
      "奧創,0.43919339776039124\n",
      "詹斯,0.4386299252510071\n",
      "狄克,0.43748682737350464\n",
      "卡普空,0.43636125326156616\n",
      "avenger,0.43632936477661133\n",
      "黑蝠,0.43603405356407166\n",
      "查尼,0.43497562408447266\n",
      "聯美,0.43410348892211914\n",
      "史帝芬,0.43381166458129883\n",
      "美國電影協會,0.4322423040866852\n",
      "ultron,0.4315573573112488\n",
      "netflix,0.4302164316177368\n",
      "smallville,0.42953741550445557\n",
      "米高梅,0.4290204346179962\n",
      "luthor,0.42820724844932556\n",
      "班恩,0.42795610427856445\n",
      "第七部,0.42749524116516113\n",
      "videogames,0.42667245864868164\n",
      "終結者,0.42607250809669495\n",
      "陰屍路,0.42522132396698\n",
      "泰瑞,0.4250909984111786\n",
      "漢克,0.42470499873161316\n",
      "斯皮爾伯格,0.4242093861103058\n",
      "電腦遊戲,0.42342302203178406\n",
      "悍將,0.4228594899177551\n",
      "aquaman,0.4225958585739136\n",
      "影業,0.4217626452445984\n",
      "史特龍,0.4209928810596466\n",
      "----------------------------\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "from gensim import models\n",
    "import logging\n",
    "\n",
    "model = models.Word2Vec.load('med250.model.bin')\n",
    "\n",
    "print(\"提供 3 種測試模式\\n\")\n",
    "print(\"輸入一個詞，則去尋找前一百個該詞的相似詞\")\n",
    "print(\"輸入兩個詞，則去計算兩個詞的餘弦相似度\")\n",
    "print(\"輸入三個詞，進行類比推理\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        query = input()\n",
    "        q_list = query.split()\n",
    "\n",
    "        if len(q_list) == 1:\n",
    "            print(\"相似詞前 100 排序\")\n",
    "            res = model.most_similar(q_list[0],topn = 100)\n",
    "            for item in res:\n",
    "                print(item[0]+\",\"+str(item[1]))\n",
    "\n",
    "        elif len(q_list) == 2:\n",
    "            print(\"計算 Cosine 相似度\")\n",
    "            res = model.similarity(q_list[0],q_list[1])\n",
    "            print(res)\n",
    "        else:\n",
    "            print(\"%s之於%s，如%s之於\" % (q_list[0],q_list[2],q_list[1]))\n",
    "            res = model.most_similar([q_list[0],q_list[1]], [q_list[2]], topn= 100)\n",
    "            for item in res:\n",
    "                print(item[0]+\",\"+str(item[1]))\n",
    "        print(\"----------------------------\")\n",
    "    except Exception as e:\n",
    "        print(repr(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
